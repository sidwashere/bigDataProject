{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c34493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense,\n",
    "                                     Flatten,\n",
    "                                     Dropout,\n",
    "                                     BatchNormalization,\n",
    "                                     Conv2D,\n",
    "                                     MaxPooling2D,)\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba65bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape view 1 data:  (13683, 32, 32)\n",
      " shape view 2 data:  (13683, 32, 32)\n",
      " shape labels data:  (13683, 1)\n"
     ]
    }
   ],
   "source": [
    "#importing data\n",
    "def load_data_from_directories(view1_dir, view2_dir, labels_dir):\n",
    "    # List all files in each directory\n",
    "    files_view1 = os.listdir(view1_dir)\n",
    "    files_view2 = os.listdir(view2_dir)\n",
    "    files_label = os.listdir(labels_dir)\n",
    "    # Initialize empty lists to store data from each view and labels\n",
    "    view1_data = []\n",
    "    view2_data = []\n",
    "    labels_data = []\n",
    "    # Iterate through the files in the directory\n",
    "    for filename in files_view1:\n",
    "        if filename.endswith('_samples_view1.npy'):\n",
    "            # Extract the common \"number\" part of the file name\n",
    "            common_number = filename.split('_')[0]\n",
    "            # Check if corresponding files exist for view2 and labels\n",
    "            if common_number + '_samples_view2.npy' in files_view2 and common_number + '_labels.npy' in files_label:\n",
    "                # Load data from the NumPy files\n",
    "                data_view1 = np.load(os.path.join(view1_dir, filename))\n",
    "                data_view2 = np.load(os.path.join(view2_dir, common_number + '_samples_view2.npy'))\n",
    "                data_labels = np.load(os.path.join(labels_dir, common_number + '_labels.npy'))\n",
    "                # Append data to respective lists\n",
    "                view1_data.append(data_view1)\n",
    "                view2_data.append(data_view2)\n",
    "                labels_data.append(data_labels)\n",
    "    view1_data = np.array(view1_data)\n",
    "    view2_data = np.array(view2_data)\n",
    "    labels_data = np.array(labels_data)\n",
    "\n",
    "    return view1_data, view2_data, labels_data\n",
    "view1_dir = (r\"C:\\Users\\user\\Desktop\\data\\view1\")\n",
    "view2_dir = (r\"C:\\Users\\user\\Desktop\\data\\view2\")\n",
    "labels_dir = (r\"C:\\Users\\user\\Desktop\\data\\labels\")\n",
    "\n",
    "view1_data, view2_data, labels_data = load_data_from_directories(view1_dir, view2_dir, labels_dir)\n",
    "\n",
    "print(\" shape view 1 data: \", view1_data.shape)\n",
    "print(\" shape view 2 data: \", view2_data.shape)\n",
    "print(\" shape labels data: \", labels_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35cc96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82a5a830",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Split the dataset into labeled, unlabeled, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset (list or array-like): The input dataset to be split.\n",
    "    - labeled_size (int): The target size for the labeled set (default: 130).\n",
    "    - test_size (float): The proportion of the dataset to include in the test split (default: 0.2).\n",
    "    - random_seed (int): Seed for reproducibility (default: None).\n",
    "\n",
    "    Returns:\n",
    "    - labeled_set_view1: Subset of the dataset with labeled data (approximately 100-130 points).\n",
    "    - labeled_set_view2: Subset of the dataset with labeled data (approximately 100-130 points).\n",
    "    - label_labeled_set: Labels corresponding to the labeled data points.\n",
    "    - unlabeled_set: Subset of the dataset with unlabeled data.\n",
    "    - test_set: Subset of the dataset for testing.\n",
    "    - label_test_set: Labels corresponding to the test data points.\n",
    "    \"\"\"\n",
    "def split_dataset(view1_data, view2_data, labels_data, labeled_size=120, test_size=0.2, random_seed=42):\n",
    "    # Split view1 data into labeled and test sets\n",
    "    labeled_set_view1, test_set_view1, label_labeled_set_view1, label_test_set_view1 = train_test_split(\n",
    "        view1_data, labels_data, train_size=labeled_size, test_size=test_size, random_state=random_seed)\n",
    "    \n",
    "    # Split view2 data into labeled and test sets\n",
    "    labeled_set_view2, test_set_view2, label_labeled_set_view2, label_test_set_view2 = train_test_split(\n",
    "        view2_data, labels_data, train_size=labeled_size, test_size=test_size, random_state=random_seed)\n",
    "    \n",
    "    return labeled_set_view1, test_set_view1, label_labeled_set_view1, label_test_set_view1, labeled_set_view2, test_set_view2, label_labeled_set_view2, label_test_set_view2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e8405cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of labeled_set_view1: (120, 32, 32)\n",
      "Shape of test_set_view1: (2737, 32, 32)\n",
      "Shape of labeled_set_view2: (120, 32, 32)\n",
      "Shape of test_set_view2: (2737, 32, 32)\n",
      "Shape of label_labeled_set_view1: (120, 1)\n",
      "Shape of label_test_set_view1: (2737, 1)\n",
      "Shape of label_labeled_set_view2: (120, 1)\n",
      "Shape of label_test_set_view2: (2737, 1)\n"
     ]
    }
   ],
   "source": [
    "labeled_set_view1, test_set_view1, label_labeled_set_view1, label_test_set_view1, labeled_set_view2, test_set_view2, label_labeled_set_view2, label_test_set_view2 = split_dataset(view1_data, view2_data, labels_data)\n",
    "\n",
    "print(\"Shape of labeled_set_view1:\", labeled_set_view1.shape)\n",
    "print(\"Shape of test_set_view1:\", test_set_view1.shape)\n",
    "print(\"Shape of labeled_set_view2:\", labeled_set_view2.shape)\n",
    "print(\"Shape of test_set_view2:\", test_set_view2.shape)\n",
    "print(\"Shape of label_labeled_set_view1:\", label_labeled_set_view1.shape)\n",
    "print(\"Shape of label_test_set_view1:\", label_test_set_view1.shape)\n",
    "print(\"Shape of label_labeled_set_view2:\", label_labeled_set_view2.shape)\n",
    "print(\"Shape of label_test_set_view2:\", label_test_set_view2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d694e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_indices = np.concatenate((labeled_set_view1, test_set_view1)).astype(int)\n",
    "unlabeled_set_view1 = np.delete(view1_data, excluded_indices, axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dff134ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_indices = np.concatenate((labeled_set_view2, test_set_view2)).astype(int)\n",
    "unlabeled_set_view2 = np.delete(view2_data, excluded_indices, axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34debff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of unlabeled_set_view1: (13679, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of unlabeled_set_view1:\", unlabeled_set_view1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f2a7c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of unlabeled_set_view2: (13680, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of unlabeled_set_view2:\", unlabeled_set_view2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb504685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Number of classes \n",
    "num_classes = len(np.unique(labels_data))\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cebe3471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38\n",
      "4/4 [==============================] - 4s 36ms/step - loss: 2.1797 - accuracy: 0.1250\n",
      "Epoch 2/38\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.8368 - accuracy: 0.1833\n",
      "Epoch 3/38\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.7236 - accuracy: 0.2167\n",
      "Epoch 4/38\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.6109 - accuracy: 0.3250\n",
      "Epoch 5/38\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.5545 - accuracy: 0.3833\n",
      "Epoch 6/38\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.4861 - accuracy: 0.4250\n",
      "Epoch 7/38\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.4031 - accuracy: 0.5167\n",
      "Epoch 8/38\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.3489 - accuracy: 0.5583\n",
      "Epoch 9/38\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.2479 - accuracy: 0.6500\n",
      "Epoch 10/38\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.1621 - accuracy: 0.6667\n",
      "Epoch 11/38\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.1263 - accuracy: 0.6500\n",
      "Epoch 12/38\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.1063 - accuracy: 0.6417\n",
      "Epoch 13/38\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.9927 - accuracy: 0.7500\n",
      "Epoch 14/38\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.9934 - accuracy: 0.6917\n",
      "Epoch 15/38\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.8028 - accuracy: 0.8250\n",
      "Epoch 16/38\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7468 - accuracy: 0.8583\n",
      "Epoch 17/38\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7177 - accuracy: 0.8333\n",
      "Epoch 18/38\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6741 - accuracy: 0.8583\n",
      "Epoch 19/38\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6788 - accuracy: 0.8167\n",
      "Epoch 20/38\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6259 - accuracy: 0.8167\n",
      "Epoch 21/38\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6124 - accuracy: 0.8500\n",
      "Epoch 22/38\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6244 - accuracy: 0.8167\n",
      "Epoch 23/38\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5898 - accuracy: 0.8333\n",
      "Epoch 24/38\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5954 - accuracy: 0.8667\n",
      "Epoch 25/38\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5753 - accuracy: 0.8250\n",
      "Epoch 26/38\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.5600 - accuracy: 0.8750\n",
      "Epoch 27/38\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.5149 - accuracy: 0.8750\n",
      "Epoch 28/38\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5816 - accuracy: 0.8500\n",
      "Epoch 29/38\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5822 - accuracy: 0.8333\n",
      "Epoch 30/38\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5319 - accuracy: 0.8333\n",
      "Epoch 31/38\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.5498 - accuracy: 0.8167\n",
      "Epoch 32/38\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.5322 - accuracy: 0.8583\n",
      "Epoch 33/38\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4620 - accuracy: 0.8750\n",
      "Epoch 34/38\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.5015 - accuracy: 0.8667\n",
      "Epoch 35/38\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5094 - accuracy: 0.8417\n",
      "Epoch 36/38\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5225 - accuracy: 0.8500\n",
      "Epoch 37/38\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5091 - accuracy: 0.8333\n",
      "Epoch 38/38\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5542 - accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f44b4b6c80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequential model\n",
    "cnn_classifier = Sequential()\n",
    "\n",
    "#1. Input Layer: BatchNormalization with input shape (32, 32, 1).\n",
    "cnn_classifier.add(BatchNormalization(input_shape=(32, 32, 1)))\n",
    "\n",
    "#2. Convolutional Layer 1: 32 filters, each with a 3x3 kernel and ReLU activation.\n",
    "cnn_classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "#3. Max Pooling Layer 1: 2x2 pooling with a stride of 2.\n",
    "cnn_classifier.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "#4. Convolutional Layer 2: 32 filters, each with a 3x3 kernel and ReLU activation.\n",
    "cnn_classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "#5. Max Pooling Layer 2: 2x2 pooling with a stride of 2.\n",
    "cnn_classifier.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "#6. Convolutional Layer 3: 32 filters, each with a 3x3 kernel and ReLU activation.\n",
    "cnn_classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "#7. Max Pooling Layer 3: 2x2 pooling with a stride of 2.\n",
    "cnn_classifier.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "#8. BatchNormalization layer\n",
    "cnn_classifier.add(BatchNormalization())\n",
    "\n",
    "#9. Flatten\n",
    "cnn_classifier.add(Flatten())\n",
    "\n",
    "#10. Dropout layer-Dropout=0.1\n",
    "cnn_classifier.add(Dropout(0.1))\n",
    "\n",
    "#11. Fully Connected Layer 1: 16 neurons, ReLU activation, and L2 regularization with a weight decay of 0.001.\n",
    "cnn_classifier.add(Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "#12. Dropout Layer with a dropout rate of 0.1.\n",
    "cnn_classifier.add(Dropout(0.1))\n",
    "\n",
    "#13. Fully Connected Layer 2: 16 neurons, ReLU activation, and L2 regularization with a weight decay of 0.001.\n",
    "cnn_classifier.add(Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "#14. Dropout layer-Dropout=0.1\n",
    "cnn_classifier.add(Dropout(0.1))\n",
    "\n",
    "#15. Output Layer: Dense layer with the number of neurons equal to the number of classes and softmax activation.\n",
    "cnn_classifier.add(Dense(6, activation='softmax'))\n",
    "\n",
    "cnn_classifier.compile(optimizer=Adam(), loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "cnn_classifier.fit(labeled_set_view1, label_labeled_set_view1, epochs=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f44b9d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=20, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=20, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=20, random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest (RF) classifier\n",
    "#Reshape\n",
    "reshaped_labeled_set_view2 = labeled_set_view2.reshape(labeled_set_view2.shape[0], -1)\n",
    "reshaped_label_labeled_view2 = label_labeled_set_view2.ravel()\n",
    "\n",
    "#Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "rf_classifier.fit(reshaped_labeled_set_view2, reshaped_label_labeled_view2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3722aa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5495 - accuracy: 0.8417\n",
      "Epoch 2/38\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4967 - accuracy: 0.8833\n",
      "Epoch 3/38\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.5414 - accuracy: 0.8250\n",
      "Epoch 4/38\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4571 - accuracy: 0.8333\n",
      "Epoch 5/38\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4330 - accuracy: 0.8333\n",
      "Epoch 6/38\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4731 - accuracy: 0.8250\n",
      "Epoch 7/38\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.4518 - accuracy: 0.8583\n",
      "Epoch 8/38\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4977 - accuracy: 0.8333\n",
      "Epoch 9/38\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4392 - accuracy: 0.8667\n",
      "Epoch 10/38\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4791 - accuracy: 0.8333\n",
      "Epoch 11/38\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.4396 - accuracy: 0.8667\n",
      "Epoch 12/38\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4953 - accuracy: 0.8333\n",
      "Epoch 13/38\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.4700 - accuracy: 0.8417\n",
      "Epoch 14/38\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4555 - accuracy: 0.8417\n",
      "Epoch 15/38\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3969 - accuracy: 0.8750\n",
      "Epoch 16/38\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4923 - accuracy: 0.8583\n",
      "Epoch 17/38\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5119 - accuracy: 0.8083\n",
      "Epoch 18/38\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4692 - accuracy: 0.8500\n",
      "Epoch 19/38\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4383 - accuracy: 0.8750\n",
      "Epoch 20/38\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4277 - accuracy: 0.8583\n",
      "Epoch 21/38\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4409 - accuracy: 0.8750\n",
      "Epoch 22/38\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4147 - accuracy: 0.8667\n",
      "Epoch 23/38\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4613 - accuracy: 0.8500\n",
      "Epoch 24/38\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4607 - accuracy: 0.8417\n",
      "Epoch 25/38\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4458 - accuracy: 0.8583\n",
      "Epoch 26/38\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4623 - accuracy: 0.8167\n",
      "Epoch 27/38\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.4578 - accuracy: 0.8500\n",
      "Epoch 28/38\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4615 - accuracy: 0.8250\n",
      "Epoch 29/38\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4796 - accuracy: 0.8417\n",
      "Epoch 30/38\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.4314 - accuracy: 0.8500\n",
      "Epoch 31/38\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4656 - accuracy: 0.8333\n",
      "Epoch 32/38\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3999 - accuracy: 0.8667\n",
      "Epoch 33/38\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3965 - accuracy: 0.8417\n",
      "Epoch 34/38\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4101 - accuracy: 0.8417\n",
      "Epoch 35/38\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4335 - accuracy: 0.8667\n",
      "Epoch 36/38\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4025 - accuracy: 0.8667\n",
      "Epoch 37/38\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4065 - accuracy: 0.8417\n",
      "Epoch 38/38\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4760 - accuracy: 0.8167\n",
      "428/428 [==============================] - 5s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "reshaped_unlabeled_set_view2 = unlabeled_set_view2.reshape(unlabeled_set_view2.shape[0], -1)\n",
    "\n",
    "def co_training(cnn_classifier, rf_classifier, labeled_set_view1, reshaped_labeled_set_view2, unlabeled_set_view1, reshaped_unlabeled_set_view2,  label_test_set_view1, label_test_set_view2 , threshold_confidence = 0.9):\n",
    "    for trained in range(10):\n",
    "        cnn_classifier.fit(labeled_set_view1, label_labeled_set_view1, epochs=38)\n",
    "        rf_classifier.fit(reshaped_labeled_set_view2, reshaped_label_labeled_view2)\n",
    "        \n",
    "        predictions1 = cnn_classifier.predict(unlabeled_set_view1)\n",
    "        predictions2 = rf_classifier.predict(reshaped_unlabeled_set_view2)\n",
    "        \n",
    "        high_confidence_view1 = [instance for instance, prediction in zip(unlabeled_set_view1, predictions1) if np.greater_equal(prediction, threshold_confidence).any()]\n",
    "        high_confidence_view2 = [instance for instance, prediction in zip(reshaped_unlabeled_set_view2, predictions2) if np.greater_equal(prediction, threshold_confidence).any()]\n",
    "        \n",
    "        labeled_set_view1 = labeled_set_view1.tolist()\n",
    "        reshaped_labeled_set_view2 = reshaped_labeled_set_view2.tolist()\n",
    "\n",
    "        labeled_set_view1.extend(high_confidence_view2)\n",
    "        reshaped_labeled_set_view2.extend(high_confidence_view1)\n",
    "        \n",
    "        unlabeled_set_view1 = np.array([instance for instance in reshaped_unlabeled_set_view2 if not np.isin(instance, high_confidence_view1).any()])\n",
    "        unlabeled_set_view2 = np.array([instance for instance in reshaped_unlabeled_set_view2 if not np.isin(instance, high_confidence_view2).any()])\n",
    "        \n",
    "        cnn_classifier.fit(labeled_set_view1, label_labeled_set_view1, epochs=38)\n",
    "        rf_classifier.fit(reshaped_labeled_set_view2, reshaped_label_labeled_view2)\n",
    "        \n",
    "    test_predictions1 = cnn_classifier.predict(label_test_set_view1)\n",
    "    test_predictions2 = rf_classifier.predict(label_test_set_view2)\n",
    "    \n",
    "    combined_predictions = [prediction1 if prediction1 == prediction2 else None for prediction1, prediction2 in zip(test_predictions1, test_predictions2)]\n",
    "\n",
    "    true_labels1 = label_labeled_set_view1\n",
    "    true_labels2 = label_labeled_set_view2\n",
    "    \n",
    "    accuracy1 = accuracy_score(true_labels1, test_predictions1)\n",
    "    accuracy2 = accuracy_score(true_labels2, test_predictions2)\n",
    "    \n",
    "    print(accuracy1)\n",
    "    print(accuracy2)\n",
    "\n",
    "    \n",
    "    return trained\n",
    "\n",
    "accuracy1, accuracy2 = co_training(cnn_classifier, rf_classifier, labeled_set_view1, reshaped_labeled_set_view2, unlabeled_set_view1, reshaped_unlabeled_set_view2, label_test_set_view1, label_test_set_view2, threshold_confidence=0.9)\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd5cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-4. pick one of the classifiers and do the supervised training with the labeled data and calculate the accuracy\n",
    "\n",
    "cnn_classifier.fit(labeled_set_view1, label_labeled_set_view1, epochs=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed16a4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2150cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2288bfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a028fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer: ''' The co-training technique outperforms the convoluted neural network model when employed alone. \n",
    "Convoluted neural networks and random forest classifiers are used as models in our co-training model, with each operating on a separate view.\n",
    "This is due to the iterative nature of co-training, which refines projected labels until a specific level of confidence is reached. \n",
    "The use of two classifiers and two perspectives provides more robust coverage. \n",
    "They also complement each other if one model has flaws. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d5cd9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad77439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2. Label Propagation for Sea Ice Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d1589f",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Apply the K-Nearest Neighbors (KNN) algorithm with a parameter configuration where n_neighbors is set to 7 for the label propagation model. Utilize one of the labeled data views and the corresponding unlabeled data from part 1 as input.\n",
    "\n",
    "    \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_labeled = labeled_set_view1\n",
    "y_labeled = labeled_set_view2\n",
    "X_unlabeled = np.concatenate((unlabeled_set_view1, unlabeled_set_view2))\n",
    "\n",
    "X = np.concatenate((X_labeled, X_unlabeled))\n",
    "y = np.concatenate((y_labeled, [-1] * len(X_unlabeled))\n",
    "                   \n",
    "# Create label propagation model with KNN algorithm\n",
    "label_prop_model = LabelPropagation(kernel='knn', n_neighbors=7)\n",
    "\n",
    "label_prop_model.fit(X, y)\n",
    "                   \n",
    "unlabeled_predictions = label_prop_model.transduction_[len(X_labeled):]\n",
    "                   \n",
    "semi_supervised_accuracy = accuracy_score(unlabeled_set_view2, unlabeled_predictions)\n",
    "print(f'Semi-Supervised Accuracy: {semi_supervised_accuracy:.2f}')\n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84759a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e93877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3. Now let's perform some experimentation and make some observations\n",
    "\n",
    "#threshold confidence= 0.8\n",
    "reshaped_unlabeled_set_view2 = unlabeled_set_view2.reshape(unlabeled_set_view2.shape[0], -1)\n",
    "\n",
    "def co_training(cnn_classifier, rf_classifier, labeled_set_view1, reshaped_labeled_set_view2, unlabeled_set_view1, reshaped_unlabeled_set_view2,  label_test_set_view1, label_test_set_view2 , threshold_confidence = 0.8):\n",
    "    for trained in range(10):\n",
    "        cnn_classifier.fit(labeled_set_view1, label_labeled_set_view1, epochs=38)\n",
    "        rf_classifier.fit(reshaped_labeled_set_view2, reshaped_label_labeled_view2)\n",
    "        \n",
    "        predictions1 = cnn_classifier.predict(unlabeled_set_view1)\n",
    "        predictions2 = rf_classifier.predict(reshaped_unlabeled_set_view2)\n",
    "        \n",
    "        high_confidence_view1 = [instance for instance, prediction in zip(unlabeled_set_view1, predictions1) if np.greater_equal(prediction, threshold_confidence).any()]\n",
    "        high_confidence_view2 = [instance for instance, prediction in zip(reshaped_unlabeled_set_view2, predictions2) if np.greater_equal(prediction, threshold_confidence).any()]\n",
    "        \n",
    "        labeled_set_view1 = labeled_set_view1.tolist()\n",
    "        reshaped_labeled_set_view2 = reshaped_labeled_set_view2.tolist()\n",
    "\n",
    "        labeled_set_view1.extend(high_confidence_view2)\n",
    "        reshaped_labeled_set_view2.extend(high_confidence_view1)\n",
    "        \n",
    "        unlabeled_set_view1 = np.array([instance for instance in reshaped_unlabeled_set_view2 if not np.isin(instance, high_confidence_view1).any()])\n",
    "        unlabeled_set_view2 = np.array([instance for instance in reshaped_unlabeled_set_view2 if not np.isin(instance, high_confidence_view2).any()])\n",
    "        \n",
    "        cnn_classifier.fit(labeled_set_view1, label_labeled_set_view1, epochs=38)\n",
    "        rf_classifier.fit(reshaped_labeled_set_view2, reshaped_label_labeled_view2)\n",
    "        \n",
    "    test_predictions1 = cnn_classifier.predict(label_test_set_view1)\n",
    "    test_predictions2 = rf_classifier.predict(label_test_set_view2)\n",
    "    \n",
    "    combined_predictions = [prediction1 if prediction1 == prediction2 else None for prediction1, prediction2 in zip(test_predictions1, test_predictions2)]\n",
    "\n",
    "    true_labels1 = label_labeled_set_view1\n",
    "    true_labels2 = label_labeled_set_view2\n",
    "    \n",
    "    accuracy1 = accuracy_score(true_labels1, test_predictions1)\n",
    "    accuracy2 = accuracy_score(true_labels2, test_predictions2)\n",
    "    \n",
    "    print(accuracy1)\n",
    "    print(accuracy2)\n",
    "\n",
    "    \n",
    "    return trained\n",
    "\n",
    "accuracy1, accuracy2 = co_training(cnn_classifier, rf_classifier, labeled_set_view1, reshaped_labeled_set_view2, unlabeled_set_view1, reshaped_unlabeled_set_view2, label_test_set_view1, label_test_set_view2, threshold_confidence=0.9)\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeca19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3. Now let's perform some experimentation and make some observations\n",
    "\n",
    "#threshold confidence= 0.7\n",
    "reshaped_unlabeled_set_view2 = unlabeled_set_view2.reshape(unlabeled_set_view2.shape[0], -1)\n",
    "\n",
    "def co_training(cnn_classifier, rf_classifier, labeled_set_view1, reshaped_labeled_set_view2, unlabeled_set_view1, reshaped_unlabeled_set_view2,  label_test_set_view1, label_test_set_view2 , threshold_confidence = 0.7):\n",
    "    for trained in range(10):\n",
    "        cnn_classifier.fit(labeled_set_view1, label_labeled_set_view1, epochs=38)\n",
    "        rf_classifier.fit(reshaped_labeled_set_view2, reshaped_label_labeled_view2)\n",
    "        \n",
    "        predictions1 = cnn_classifier.predict(unlabeled_set_view1)\n",
    "        predictions2 = rf_classifier.predict(reshaped_unlabeled_set_view2)\n",
    "        \n",
    "        high_confidence_view1 = [instance for instance, prediction in zip(unlabeled_set_view1, predictions1) if np.greater_equal(prediction, threshold_confidence).any()]\n",
    "        high_confidence_view2 = [instance for instance, prediction in zip(reshaped_unlabeled_set_view2, predictions2) if np.greater_equal(prediction, threshold_confidence).any()]\n",
    "        \n",
    "        labeled_set_view1 = labeled_set_view1.tolist()\n",
    "        reshaped_labeled_set_view2 = reshaped_labeled_set_view2.tolist()\n",
    "\n",
    "        labeled_set_view1.extend(high_confidence_view2)\n",
    "        reshaped_labeled_set_view2.extend(high_confidence_view1)\n",
    "        \n",
    "        unlabeled_set_view1 = np.array([instance for instance in reshaped_unlabeled_set_view2 if not np.isin(instance, high_confidence_view1).any()])\n",
    "        unlabeled_set_view2 = np.array([instance for instance in reshaped_unlabeled_set_view2 if not np.isin(instance, high_confidence_view2).any()])\n",
    "        \n",
    "        cnn_classifier.fit(labeled_set_view1, label_labeled_set_view1, epochs=38)\n",
    "        rf_classifier.fit(reshaped_labeled_set_view2, reshaped_label_labeled_view2)\n",
    "        \n",
    "    test_predictions1 = cnn_classifier.predict(label_test_set_view1)\n",
    "    test_predictions2 = rf_classifier.predict(label_test_set_view2)\n",
    "    \n",
    "    combined_predictions = [prediction1 if prediction1 == prediction2 else None for prediction1, prediction2 in zip(test_predictions1, test_predictions2)]\n",
    "\n",
    "    true_labels1 = label_labeled_set_view1\n",
    "    true_labels2 = label_labeled_set_view2\n",
    "    \n",
    "    accuracy1 = accuracy_score(true_labels1, test_predictions1)\n",
    "    accuracy2 = accuracy_score(true_labels2, test_predictions2)\n",
    "    \n",
    "    print(accuracy1)\n",
    "    print(accuracy2)\n",
    "\n",
    "    \n",
    "    return trained\n",
    "\n",
    "accuracy1, accuracy2 = co_training(cnn_classifier, rf_classifier, labeled_set_view1, reshaped_labeled_set_view2, unlabeled_set_view1, reshaped_unlabeled_set_view2, label_test_set_view1, label_test_set_view2, threshold_confidence=0.9)\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66faf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3. Now let's perform some experimentation and make some observations\n",
    "\n",
    "#threshold confidence= 0.6\n",
    "reshaped_unlabeled_set_view2 = unlabeled_set_view2.reshape(unlabeled_set_view2.shape[0], -1)\n",
    "\n",
    "def co_training(cnn_classifier, rf_classifier, labeled_set_view1, reshaped_labeled_set_view2, unlabeled_set_view1, reshaped_unlabeled_set_view2,  label_test_set_view1, label_test_set_view2 , threshold_confidence = 0.6):\n",
    "    for trained in range(10):\n",
    "        cnn_classifier.fit(labeled_set_view1, label_labeled_set_view1, epochs=38)\n",
    "        rf_classifier.fit(reshaped_labeled_set_view2, reshaped_label_labeled_view2)\n",
    "        \n",
    "        predictions1 = cnn_classifier.predict(unlabeled_set_view1)\n",
    "        predictions2 = rf_classifier.predict(reshaped_unlabeled_set_view2)\n",
    "        \n",
    "        high_confidence_view1 = [instance for instance, prediction in zip(unlabeled_set_view1, predictions1) if np.greater_equal(prediction, threshold_confidence).any()]\n",
    "        high_confidence_view2 = [instance for instance, prediction in zip(reshaped_unlabeled_set_view2, predictions2) if np.greater_equal(prediction, threshold_confidence).any()]\n",
    "        \n",
    "        labeled_set_view1 = labeled_set_view1.tolist()\n",
    "        reshaped_labeled_set_view2 = reshaped_labeled_set_view2.tolist()\n",
    "\n",
    "        labeled_set_view1.extend(high_confidence_view2)\n",
    "        reshaped_labeled_set_view2.extend(high_confidence_view1)\n",
    "        \n",
    "        unlabeled_set_view1 = np.array([instance for instance in reshaped_unlabeled_set_view2 if not np.isin(instance, high_confidence_view1).any()])\n",
    "        unlabeled_set_view2 = np.array([instance for instance in reshaped_unlabeled_set_view2 if not np.isin(instance, high_confidence_view2).any()])\n",
    "        \n",
    "        cnn_classifier.fit(labeled_set_view1, label_labeled_set_view1, epochs=38)\n",
    "        rf_classifier.fit(reshaped_labeled_set_view2, reshaped_label_labeled_view2)\n",
    "        \n",
    "    test_predictions1 = cnn_classifier.predict(label_test_set_view1)\n",
    "    test_predictions2 = rf_classifier.predict(label_test_set_view2)\n",
    "    \n",
    "    combined_predictions = [prediction1 if prediction1 == prediction2 else None for prediction1, prediction2 in zip(test_predictions1, test_predictions2)]\n",
    "\n",
    "    true_labels1 = label_labeled_set_view1\n",
    "    true_labels2 = label_labeled_set_view2\n",
    "    \n",
    "    accuracy1 = accuracy_score(true_labels1, test_predictions1)\n",
    "    accuracy2 = accuracy_score(true_labels2, test_predictions2)\n",
    "    \n",
    "    print(accuracy1)\n",
    "    print(accuracy2)\n",
    "\n",
    "    \n",
    "    return trained\n",
    "\n",
    "accuracy1, accuracy2 = co_training(cnn_classifier, rf_classifier, labeled_set_view1, reshaped_labeled_set_view2, unlabeled_set_view1, reshaped_unlabeled_set_view2, label_test_set_view1, label_test_set_view2, threshold_confidence=0.9)\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f28492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3 answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e7a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-2. Change the parameters of the K-Nearest Neighbors (KNN) algorithm for Label Propagation (part 2) with the values 3, 5, and 10, and explain what you understand about these parameter adjustments.\n",
    "\n",
    " #Apply the K-Nearest Neighbors (KNN) algorithm with a parameter configuration where n_neighbors is set to 3 for the label propagation model. Utilize one of the labeled data views and the corresponding unlabeled data from part 1 as input.\n",
    "\n",
    "    \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_labeled = labeled_set_view1\n",
    "y_labeled = labeled_set_view2\n",
    "X_unlabeled = np.concatenate((unlabeled_set_view1, unlabeled_set_view2))\n",
    "\n",
    "X = np.concatenate((X_labeled, X_unlabeled))\n",
    "y = np.concatenate((y_labeled, [-1] * len(X_unlabeled))\n",
    "                   \n",
    "# Create label propagation model with KNN algorithm\n",
    "label_prop_model = LabelPropagation(kernel='knn', n_neighbors=3)\n",
    "\n",
    "label_prop_model.fit(X, y)\n",
    "                   \n",
    "unlabeled_predictions = label_prop_model.transduction_[len(X_labeled):]\n",
    "                   \n",
    "semi_supervised_accuracy = accuracy_score(unlabeled_set_view2, unlabeled_predictions)\n",
    "print(f'Semi-Supervised Accuracy: {semi_supervised_accuracy:.2f}')\n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a464b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Apply the K-Nearest Neighbors (KNN) algorithm with a parameter configuration where n_neighbors is set to 5 for the label propagation model. Utilize one of the labeled data views and the corresponding unlabeled data from part 1 as input.\n",
    "\n",
    "    \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_labeled = labeled_set_view1\n",
    "y_labeled = labeled_set_view2\n",
    "X_unlabeled = np.concatenate((unlabeled_set_view1, unlabeled_set_view2))\n",
    "\n",
    "X = np.concatenate((X_labeled, X_unlabeled))\n",
    "y = np.concatenate((y_labeled, [-1] * len(X_unlabeled))\n",
    "                   \n",
    "# Create label propagation model with KNN algorithm\n",
    "label_prop_model = LabelPropagation(kernel='knn', n_neighbors=5)\n",
    "\n",
    "label_prop_model.fit(X, y)\n",
    "                   \n",
    "unlabeled_predictions = label_prop_model.transduction_[len(X_labeled):]\n",
    "                   \n",
    "semi_supervised_accuracy = accuracy_score(unlabeled_set_view2, unlabeled_predictions)\n",
    "print(f'Semi-Supervised Accuracy: {semi_supervised_accuracy:.2f}')\n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c302d803",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Apply the K-Nearest Neighbors (KNN) algorithm with a parameter configuration where n_neighbors is set to 10 for the label propagation model. Utilize one of the labeled data views and the corresponding unlabeled data from part 1 as input.\n",
    "\n",
    "    \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_labeled = labeled_set_view1\n",
    "y_labeled = labeled_set_view2\n",
    "X_unlabeled = np.concatenate((unlabeled_set_view1, unlabeled_set_view2))\n",
    "\n",
    "X = np.concatenate((X_labeled, X_unlabeled))\n",
    "y = np.concatenate((y_labeled, [-1] * len(X_unlabeled))\n",
    "                   \n",
    "# Create label propagation model with KNN algorithm\n",
    "label_prop_model = LabelPropagation(kernel='knn', n_neighbors=7)\n",
    "\n",
    "label_prop_model.fit(X, y)\n",
    "                   \n",
    "unlabeled_predictions = label_prop_model.transduction_[len(X_labeled):]\n",
    "                   \n",
    "semi_supervised_accuracy = accuracy_score(unlabeled_set_view2, unlabeled_predictions)\n",
    "print(f'Semi-Supervised Accuracy: {semi_supervised_accuracy:.2f}')\n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e97502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model\n",
    "cnn_classifier = Sequential()\n",
    "\n",
    "#1. Input Layer: BatchNormalization with input shape (32, 32, 1).\n",
    "cnn_classifier.add(BatchNormalization(input_shape=(32, 32, 1)))\n",
    "\n",
    "#2. Convolutional Layer 1: 32 filters, each with a 3x3 kernel and ReLU activation.\n",
    "cnn_classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "#3. Max Pooling Layer 1: 2x2 pooling with a stride of 2.\n",
    "cnn_classifier.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "\n",
    "#8. BatchNormalization layer\n",
    "cnn_classifier.add(BatchNormalization())\n",
    "\n",
    "#9. Flatten\n",
    "cnn_classifier.add(Flatten())\n",
    "\n",
    "#10. Dropout layer-Dropout=0.1\n",
    "cnn_classifier.add(Dropout(0.1))\n",
    "\n",
    "#11. Fully Connected Layer 1: 16 neurons, ReLU activation, and L2 regularization with a weight decay of 0.001.\n",
    "cnn_classifier.add(Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "#12. Dropout Layer with a dropout rate of 0.1.\n",
    "cnn_classifier.add(Dropout(0.1))\n",
    "\n",
    "#13. Fully Connected Layer 2: 16 neurons, ReLU activation, and L2 regularization with a weight decay of 0.001.\n",
    "cnn_classifier.add(Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "#14. Dropout layer-Dropout=0.1\n",
    "cnn_classifier.add(Dropout(0.1))\n",
    "\n",
    "#15. Output Layer: Dense layer with the number of neurons equal to the number of classes and softmax activation.\n",
    "cnn_classifier.add(Dense(6, activation='softmax'))\n",
    "\n",
    "cnn_classifier.compile(optimizer=Adam(), loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "cnn_classifier.fit(labeled_set_view1, label_labeled_set_view1, epochs=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae46f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest (RF) classifier\n",
    "#Reshape\n",
    "reshaped_labeled_set_view2 = labeled_set_view2.reshape(labeled_set_view2.shape[0], -1)\n",
    "reshaped_label_labeled_view2 = label_labeled_set_view2.ravel()\n",
    "\n",
    "#Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=1, random_state=42)\n",
    "rf_classifier.fit(reshaped_labeled_set_view2, reshaped_label_labeled_view2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9464815",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_unlabeled_set_view2 = unlabeled_set_view2.reshape(unlabeled_set_view2.shape[0], -1)\n",
    "\n",
    "def co_training(cnn_classifier, rf_classifier, labeled_set_view1, reshaped_labeled_set_view2, unlabeled_set_view1, reshaped_unlabeled_set_view2,  label_test_set_view1, label_test_set_view2 , threshold_confidence = 0.9):\n",
    "    for trained in range(10):\n",
    "        cnn_classifier.fit(labeled_set_view1, label_labeled_set_view1, epochs=38)\n",
    "        rf_classifier.fit(reshaped_labeled_set_view2, reshaped_label_labeled_view2)\n",
    "        \n",
    "        predictions1 = cnn_classifier.predict(unlabeled_set_view1)\n",
    "        predictions2 = rf_classifier.predict(reshaped_unlabeled_set_view2)\n",
    "        \n",
    "        high_confidence_view1 = [instance for instance, prediction in zip(unlabeled_set_view1, predictions1) if np.greater_equal(prediction, threshold_confidence).any()]\n",
    "        high_confidence_view2 = [instance for instance, prediction in zip(reshaped_unlabeled_set_view2, predictions2) if np.greater_equal(prediction, threshold_confidence).any()]\n",
    "        \n",
    "        labeled_set_view1 = labeled_set_view1.tolist()\n",
    "        reshaped_labeled_set_view2 = reshaped_labeled_set_view2.tolist()\n",
    "\n",
    "        labeled_set_view1.extend(high_confidence_view2)\n",
    "        reshaped_labeled_set_view2.extend(high_confidence_view1)\n",
    "        \n",
    "        unlabeled_set_view1 = np.array([instance for instance in reshaped_unlabeled_set_view2 if not np.isin(instance, high_confidence_view1).any()])\n",
    "        unlabeled_set_view2 = np.array([instance for instance in reshaped_unlabeled_set_view2 if not np.isin(instance, high_confidence_view2).any()])\n",
    "        \n",
    "        cnn_classifier.fit(labeled_set_view1, label_labeled_set_view1, epochs=38)\n",
    "        rf_classifier.fit(reshaped_labeled_set_view2, reshaped_label_labeled_view2)\n",
    "        \n",
    "    test_predictions1 = cnn_classifier.predict(label_test_set_view1)\n",
    "    test_predictions2 = rf_classifier.predict(label_test_set_view2)\n",
    "    \n",
    "    combined_predictions = [prediction1 if prediction1 == prediction2 else None for prediction1, prediction2 in zip(test_predictions1, test_predictions2)]\n",
    "\n",
    "    true_labels1 = label_labeled_set_view1\n",
    "    true_labels2 = label_labeled_set_view2\n",
    "    \n",
    "    accuracy1 = accuracy_score(true_labels1, test_predictions1)\n",
    "    accuracy2 = accuracy_score(true_labels2, test_predictions2)\n",
    "    \n",
    "    print(accuracy1)\n",
    "    print(accuracy2)\n",
    "\n",
    "    \n",
    "    return trained\n",
    "\n",
    "accuracy1, accuracy2 = co_training(cnn_classifier, rf_classifier, labeled_set_view1, reshaped_labeled_set_view2, unlabeled_set_view1, reshaped_unlabeled_set_view2, label_test_set_view1, label_test_set_view2, threshold_confidence=0.9)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97956b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn_classifier.fit(labeled_set_II, label_labeled_set_II, epochs=10)\n",
    "predictions = cnn_classifier.predict(test_set)\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
